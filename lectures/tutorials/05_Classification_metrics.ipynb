{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d664aa01-6888-4461-a1eb-8fd902dc6b91",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](../img/330-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b55dff-2796-4c7a-ae5f-781f78855bdd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Tutorial 5\n",
    "\n",
    "UBC 2024-25\n",
    "\n",
    "## Outline\n",
    "\n",
    "During this tutorial, we will focus on calculating and understanding classification metrics, evaluating different classifiers, and addressing class imbalances.\n",
    "\n",
    "All questions can be discussed with your classmates and the TAs - this is not a graded exercise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c2277-eaf0-4dcb-9e0d-1020e2aa94be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(\"..\"), \"code\"))\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from plotting_functions import *\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "from IPython.display import Image\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "DATA_DIR = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396c985f-1024-4ee2-a422-f24b149f4e0e",
   "metadata": {},
   "source": [
    "For this exercise, we will use the same dataset on fraudulent and non-fraudulent transactions used in class (based on Kaggle's [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud) data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6260850-951c-46af-aeb5-8afd412142d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset will be loaded using a URL instead of a CSV file\n",
    "DATA_URL = \"https://github.com/firasm/bits/raw/refs/heads/master/creditcard.csv\"\n",
    "\n",
    "cc_df = pd.read_csv(DATA_URL, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92900d-4ff9-49bb-b92b-e3ba646d6ab3",
   "metadata": {},
   "source": [
    "Even our reduced version of this dataset is still large enough (almost 200k samples) that we can skip cross-validation, and create single training, validation and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34d826-8f80-4b77-85c0-4a075632db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split to create the test set\n",
    "train_df, test_df = train_test_split(cc_df, test_size=0.3, random_state=111)\n",
    "\n",
    "X_train_big, y_train_big = train_df.drop(columns=[\"Class\", \"Time\"]), train_df[\"Class\"]\n",
    "\n",
    "X_test, y_test = test_df.drop(columns=[\"Class\", \"Time\"]), test_df[\"Class\"] \n",
    "\n",
    "# Additional split to separate training and validation samples\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_big, y_train_big, test_size=0.3, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cccc11-c266-439a-8629-74b9db16591b",
   "metadata": {},
   "source": [
    "We also know that this dataset is heavily unbalanced toward the negative class (non-fraud). Even a DummyClassifier would get more than 99% accuracy on this classification problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21185844-f37e-496e-bfd7-ba9fb28917eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"Class\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ca7445-68fd-4181-a986-39adf85b76dd",
   "metadata": {},
   "source": [
    "### <font color='red'>Question 1</font>\n",
    "\n",
    "Let's start by training a logistic regression model to separate the two classes included in this dataset. Then, observe the resulting confusion matrix, and compute **by hand** accuracy, recall and precision (you may use a calculator, but not the functions included in scikit-learn, like `classification_report`).\n",
    "\n",
    "You may check your results using `classification_report` once you are done, but learning to calculate these metrics by looking at a confusion matrix is a good way to understand them.\n",
    "\n",
    "Use the results to describe, for a non-expert audience, the behaviour of this classifier, answering questions such as:\n",
    "- Is this classifier effective at finding fraudulent transactions?\n",
    "- When this classifier reports a fraudulent transaction, are we confident that it is right?\n",
    "- Is this classifier more likely to misclassify a fraud as a valid transaction, or vice-versa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028dd75-ad79-456b-af1a-528ac52a24d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay  \n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe.fit(X_train, y_train)\n",
    "cm = ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe, X_valid, y_valid, values_format=\"d\", display_labels=[\"Non fraud\", \"fraud\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1818fe6b-e523-43c7-9cb5-c66fdac58e6a",
   "metadata": {},
   "source": [
    "### <font color='red'>Question 2</font>\n",
    "\n",
    "Next, we are going to try to address the problem of class imbalance as explained in this [video](https://www.youtube.com/watch?v=jHaKRCFb6Qw), by changing the weights of the samples.\n",
    "\n",
    "Complete the code below to assign a weight of 50 to the positive class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293f208-2ca1-4304-bf97-ca6250fa752d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe_lr_weight = make_pipeline(\n",
    "    StandardScaler(), LogisticRegression(max_iter=500, class_weight={0: 1, 1: 50}) # add parameters here\n",
    ")\n",
    "\n",
    "pipe_lr_weight.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af0eb7-1e7e-40c2-a414-960e791a1c80",
   "metadata": {},
   "source": [
    "### <font color='red'>Question 3</font>\n",
    "\n",
    "Now, repeat the analysis you did in Question 1 (you can use `classification_report` this time). \n",
    "\n",
    "Again, imagine to be addressing a general audience: \n",
    "- How would you describe the performance of this classifier, compared to the first one we tried?\n",
    "- Is this classifier better or worse at finding fraudulent transactions?\n",
    "- When this classifier reports a fraudulent transaction, are we more or less confident that it is right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de2d95-0231-45aa-aad5-c75be4fb5b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c8baea4-f9c0-4675-bc06-797a0e74e619",
   "metadata": {},
   "source": [
    "### <font color='red'>Question 4</font>\n",
    "\n",
    "Before settling on a model, we will make one more attempt at changing the weights of the classes, this time using the `class_weight=\"balanced\"` parameter.\n",
    "\n",
    "The code is provided below. The scikit-learn documentation says that:\n",
    "\n",
    "- \"If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y))\". \n",
    "\n",
    "According to this explanation, what is now the relative weight of the positive class? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bdf7c9-93b3-4fc0-939a-4343182efc9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe_lr_balanced = make_pipeline(\n",
    "    StandardScaler(), LogisticRegression(max_iter=500, class_weight=\"balanced\")\n",
    ")\n",
    "pipe_lr_balanced.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b9010a-6c36-4bcf-8a72-f6cf138eab99",
   "metadata": {},
   "source": [
    "### <font color='red'>Question 5</font>\n",
    "\n",
    "One more time, repeat your analysis, explaining your results to a general audience: \n",
    "- How would you describe the performance of this classifier, compared to the previous two?\n",
    "- Is this classifier better or worse at finding fraudulent transactions?\n",
    "- When this classifier reports a fraudulent transaction, are we more or less confident that it is right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82298112-aeb6-4ae5-aaa1-66ca79002acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e540715-c95d-440a-ba34-1e6ae37ed50f",
   "metadata": {},
   "source": [
    "### <font color='red'>Question 6</font>\n",
    "\n",
    "The lecture notes state:\n",
    "\n",
    "- AUC can be interpreted as evaluating the **ranking** of positive examples.\n",
    "- That is equivalent to the probability of a randomly picked positive point having a higher score according to the classifier than a randomly picked point from the negative class. \n",
    "- AUC of 1.0 means all positive points have a higher score than all negative points.\n",
    "\n",
    "Based on these information, which one of the three classifiers that we trained do you expect to have the highest AUC score?\n",
    "\n",
    "Compute the scores below to verify your answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c47a56c-b266-4398-8374-33b67582aa6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087eaa8-9f69-4c81-ac27-00860cd26480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a82c04c6-de01-406f-bf36-3c6a40ccb74c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## ML fairness activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea4348c-53ae-4741-a72e-09cccba89ba6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "AI/ML systems can give the illusion of objectivity as they are derived from seemingly unbiased data & algorithm. However, human are inherently biased and AI/ML systems, if not carefully evaluated, can even further amplify the existing inequities and systemic bias in our society.  \n",
    "\n",
    "How do we make sure our AI/ML systems are *fair*? Which metrics can we use to quantify 'fairness' in AI/ML systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e522aa-7ed4-415c-a606-75ac9ea99862",
   "metadata": {},
   "source": [
    "Let's examine this on [the adult census data set](https://www.kaggle.com/uciml/adult-census-income). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c29ad0-4adb-43ab-b50b-1518f8cb3727",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "census_df = pd.read_csv(DATA_DIR + \"adult.csv\")\n",
    "census_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef879f25-1fde-4425-8167-549466ba1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(census_df, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf78f20-f0ff-44f7-a2ed-176d6b04037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3feb7b1-f9e1-4ead-bdc3-d3418aa43ad6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing \n",
    "\n",
    "You may skip ahead or review as additional example of preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f086e89-ad08-4d76-b5d1-e3d267467fbd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_df_nan = train_df.replace(\"?\", np.nan)\n",
    "test_df_nan = test_df.replace(\"?\", np.nan)\n",
    "train_df_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf311b-1b8a-40f6-8bef-9bd23690cb98",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's identify numeric and categorical features\n",
    "\n",
    "numeric_features = [\n",
    "    \"age\",\n",
    "    \"capital.gain\",\n",
    "    \"capital.loss\",\n",
    "    \"hours.per.week\",\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"workclass\",\n",
    "    \"marital.status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"native.country\",\n",
    "]\n",
    "\n",
    "ordinal_features = [\"education\"]\n",
    "binary_features = [\n",
    "    \"sex\"\n",
    "]  # Not binary in general but in this particular dataset it seems to have only two possible values\n",
    "drop_features = [\"education.num\", \"fnlwgt\"]\n",
    "target = \"income\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17e772-f8d5-4735-91f1-79ad1ed1a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_levels = [\n",
    "    \"Preschool\",\n",
    "    \"1st-4th\",\n",
    "    \"5th-6th\",\n",
    "    \"7th-8th\",\n",
    "    \"9th\",\n",
    "    \"10th\",\n",
    "    \"11th\",\n",
    "    \"12th\",\n",
    "    \"HS-grad\",\n",
    "    \"Prof-school\",\n",
    "    \"Assoc-voc\",\n",
    "    \"Assoc-acdm\",\n",
    "    \"Some-college\",\n",
    "    \"Bachelors\",\n",
    "    \"Masters\",\n",
    "    \"Doctorate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dcea89-1f68-4831-a4d8-d0981a2b5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(education_levels) == set(train_df[\"education\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97549d9a-c179-4351-8956-08aa7b9c6e98",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_df_nan.drop(columns=[target])\n",
    "y_train = train_df_nan[target]\n",
    "\n",
    "X_test = test_df_nan.drop(columns=[target])\n",
    "y_test = test_df_nan[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea0a4d-e8c3-4851-8153-52edc7cb1dc0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "ordinal_transformer = OrdinalEncoder(categories=[education_levels], dtype=int)\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    ")\n",
    "\n",
    "binary_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(drop=\"if_binary\", dtype=int),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (ordinal_transformer, ordinal_features),\n",
    "    (binary_transformer, binary_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be73a7-a7ae-4fe2-bd05-0cd20bd4448f",
   "metadata": {},
   "source": [
    "### Model training and evaluation\n",
    "\n",
    "This dataset is a bit unbalanced (see count below), so we are going to train a logistic regression model with `class_weight=\"balanced\"` to account for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c4a42-e9b2-4200-9a67-9b3e7de5af33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af442ad8-530a-438d-a39f-82f3365abf17",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(\n",
    "    preprocessor, LogisticRegression(class_weight=\"balanced\", max_iter=1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b27851-0637-49fa-ad72-6136b6890403",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f533c2f-cb89-4a50-bf45-5098078b6286",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(pipe_lr, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b833c2-696e-48ca-a6da-f346db872607",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's examine confusion matrix separately for the two genders we have in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1056b-99bb-4ad5-88b1-579f153c0e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc = preprocessor.fit_transform(X_train)\n",
    "preprocessor.named_transformers_[\"pipeline-2\"][\"onehotencoder\"].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d78826f-c296-48fe-9263-c1665d6565e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_female = X_test.query(\"sex=='Female'\")  # X where sex is female\n",
    "X_male = X_test.query(\"sex=='Male'\")  # X where sex is male\n",
    "\n",
    "y_female = y_test[X_female.index]  # y where sex is female\n",
    "y_male = y_test[X_male.index]  # y where sex is male"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052048b5-7b38-468e-ac60-f528095a7f38",
   "metadata": {},
   "source": [
    "**Get predictions for `X_female` and `y_male` with `pipe_lr`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96825bd-093c-4ae2-a5eb-d75a82d9652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_preds = pipe_lr.predict(X_female)\n",
    "male_preds = pipe_lr.predict(X_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd7bc4-4af9-449f-b24a-e40d6a2d272b",
   "metadata": {},
   "source": [
    "Examine the accuracy and confusion matrix for female and male classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca13aa2-755a-4714-87dd-52fabea747c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_female, female_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4adf96-a832-4658-b079-7ba1fe6aea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_male, male_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade3f94-72a6-4e01-8567-2025616308bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot the female confusion matrix\n",
    "female_cm = ConfusionMatrixDisplay.from_estimator(pipe_lr, X_female, y_female, normalize=\"true\");\n",
    "axes[0].set_title('Confusion Matrix - Female');\n",
    "female_cm.plot(ax=axes[0]);\n",
    "\n",
    "\n",
    "# Plot the male confusion matrix\n",
    "male_cm = ConfusionMatrixDisplay.from_estimator(pipe_lr, X_male, y_male, normalize=\"true\");\n",
    "axes[1].set_title('Confusion Matrix - Male');\n",
    "male_cm.plot(ax=axes[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c1bf20-8d8f-48f9-a6b7-736e78c54ce1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### ❓❓ Questions for group discussion\n",
    "\n",
    "Let's assume that a company is using this classifier for loan approval with a simple rule that if the income is >=50K, approve the loan else reject the loan. \n",
    "\n",
    "In your group, discuss the questions below. \n",
    "\n",
    "1. Which group has a higher accuracy?\n",
    "2. Which group has a higher precision for class >50K? What about recall for class >50K?\n",
    "3. Will both groups have more or less the same proportion of people with approved loans? \n",
    "4. If a male and a female have both a certain level of income, will they have the same chance of getting the loan?\n",
    "5. Banks want to avoid approving unqualified applications (false positives) because default loan could have detrimental effects for them. Compare the false positive rates for the two groups.    \n",
    "6. Overall, do you think this income classifier will fairly treat both groups? What will be the consequences of using this classifier in loan approval application? \n",
    "7. Do you think the effect will still exist if the sex feature is removed from the model (but you still have it available separately to do the two confusion matrices)? \n",
    "8. Are there any other groups in this dataset worth examining for biases? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1fa68-02fc-4969-b0d5-8375eb2d84b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "cpsc330"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
